{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/DSApps_logo_small.jpg\">\n",
    "\n",
    "# DSApps 2023 @ TAU: Assignment 3\n",
    "\n",
    "### Giora Simchoni\n",
    "\n",
    "### Some Pandas and Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome\n",
    "\n",
    "Welcome to Assignment 3 in Python!\n",
    "\n",
    "Remember:\n",
    "\n",
    "* You can play with the assignment in Playground mode, but:\n",
    "* Only your private Github repository assigned to you by the course admin will be cloned and graded (Submission mode, see instructions [here](https://github.com/DSApps-2023/Class_Slides/blob/main/Apps_of_DS_HW.pdf))\n",
    "* Like any other University assignment, your work should remain private\n",
    "* You need to `git clone` your private Github repository locally as explained [here](https://github.com/DSApps-2023/Class_Slides/blob/main/Apps_of_DS_HW.pdf)\n",
    "* You need to uncomment the starter code inside the chunk, replace the `### YOUR CODE HERE ###`, run the chunk and see that you're getting the expected result\n",
    "* Pay attention to what you're asked to do and the required output\n",
    "* For example, using a *different* function than the one you were specifically asked to use, will decrease your score (unless you amaze me)\n",
    "* Your notebook should run smoothly from start to end if someone presses in the Jupyter toolbar Kernel --> Restart & Run All\n",
    "* When you're done save the entire notebook into a html file, this is the file that would be graded\n",
    "* You can add other files but do not delete any files\n",
    "* Commit your work and push to your private Github repository as explained [here](https://github.com/DSApps-2023/Class_Slides/blob/main/Apps_of_DS_HW.pdf)\n",
    "\n",
    "This assignemtnt is due: 8/5 23:59\n",
    "\n",
    "### Libraries\n",
    "\n",
    "These are the libraries you will need. If you don't have them, you need to uncomment the `!pip install` line and install them first (you can also just copy this command to a terminal and do it there if you don't want all the output printed in this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install matplotlib numpy scipy pandas beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Pandas\n",
    "\n",
    "###### (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behold the `fifa_wide` DF. There's only so much we can do with it in current form. Make `fifa_wide` into `fifa_long`, a table with 4 columns (say `['Country', 'Continent', 'Year', 'Rank']`) and 15 rows, holding for each country, for each World Cup year, its Rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>2014</th>\n",
       "      <th>2018</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>Europe</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Europe</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>South America</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>South America</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country      Continent  2014  2018  2022\n",
       "0     France         Europe     7     1     2\n",
       "1    Germany         Europe     1    22    17\n",
       "2      Spain         Europe    23    10    13\n",
       "3  Argentina  South America     2    16     1\n",
       "4     Brazil  South America     4     6     7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifa_d = {'Country': ['France', 'Germany', 'Spain', 'Argentina', 'Brazil'],\n",
    "      'Continent': ['Europe', 'Europe', 'Europe', 'South America', 'South America'],\n",
    "      '2014': [7, 1, 23, 2, 4],\n",
    "      '2018': [1, 22, 10, 16, 6],\n",
    "      '2022': [2, 17, 13, 1, 7]}\n",
    "\n",
    "fifa_wide = pd.DataFrame(fifa_d)\n",
    "fifa_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2014</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2014</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>South America</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>South America</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2018</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>South America</td>\n",
       "      <td>2018</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>South America</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>France</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2022</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Europe</td>\n",
       "      <td>2022</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>South America</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>South America</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Country      Continent  Year  Rank\n",
       "0      France         Europe  2014     7\n",
       "1     Germany         Europe  2014     1\n",
       "2       Spain         Europe  2014    23\n",
       "3   Argentina  South America  2014     2\n",
       "4      Brazil  South America  2014     4\n",
       "5      France         Europe  2018     1\n",
       "6     Germany         Europe  2018    22\n",
       "7       Spain         Europe  2018    10\n",
       "8   Argentina  South America  2018    16\n",
       "9      Brazil  South America  2018     6\n",
       "10     France         Europe  2022     2\n",
       "11    Germany         Europe  2022    17\n",
       "12      Spain         Europe  2022    13\n",
       "13  Argentina  South America  2022     1\n",
       "14     Brazil  South America  2022     7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fifa_long = pd.melt(fifa_wide, id_vars=('Country','Continent'), \n",
    "                    value_vars=['2014','2018','2022'], \n",
    "                    var_name=\"Year\", \n",
    "                    value_name=\"Rank\")\n",
    "\n",
    "fifa_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bME6d1ZfbmsI"
   },
   "source": [
    "We have downloaded from [Gapminder data repository](https://www.gapminder.org/data/) the life expectancy data for all countries in the years 1900-1999. \n",
    "\n",
    "* Upload the `life_expectancy_years.csv` file from Moodle, however you want.\n",
    "* Extract from this dataset countries that have data for all years in the range 1900-1999 (i.e. you should discard countires with `Nan` values in years 1900-1999).\n",
    "* You should get 184 countries.\n",
    "* Create for each of these the average age for each decade (1900-1909, 1910-1919,...), resulting with a matrix of 184 countries (rows) times 10 decades averages (the country's name is an extra column, so 11 columns).\n",
    "\n",
    "\n",
    "**Important:** There are many ways to do this manipulation. Looping isn't a sin, but you should know where to use it.\n",
    "\n",
    "**Sanity check:** the maximum value at the 90s (1990-1999) should be about `80.11`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qh4Yxv2LbmsL"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>1800</th>\n",
       "      <th>1801</th>\n",
       "      <th>1802</th>\n",
       "      <th>1803</th>\n",
       "      <th>1804</th>\n",
       "      <th>1805</th>\n",
       "      <th>1806</th>\n",
       "      <th>1807</th>\n",
       "      <th>1808</th>\n",
       "      <th>...</th>\n",
       "      <th>2091</th>\n",
       "      <th>2092</th>\n",
       "      <th>2093</th>\n",
       "      <th>2094</th>\n",
       "      <th>2095</th>\n",
       "      <th>2096</th>\n",
       "      <th>2097</th>\n",
       "      <th>2098</th>\n",
       "      <th>2099</th>\n",
       "      <th>2100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>28.1</td>\n",
       "      <td>28.1</td>\n",
       "      <td>28.1</td>\n",
       "      <td>...</td>\n",
       "      <td>76.5</td>\n",
       "      <td>76.6</td>\n",
       "      <td>76.7</td>\n",
       "      <td>76.9</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.1</td>\n",
       "      <td>77.3</td>\n",
       "      <td>77.4</td>\n",
       "      <td>77.5</td>\n",
       "      <td>77.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>35.4</td>\n",
       "      <td>35.4</td>\n",
       "      <td>35.4</td>\n",
       "      <td>35.4</td>\n",
       "      <td>35.4</td>\n",
       "      <td>35.4</td>\n",
       "      <td>35.4</td>\n",
       "      <td>35.4</td>\n",
       "      <td>35.4</td>\n",
       "      <td>...</td>\n",
       "      <td>87.4</td>\n",
       "      <td>87.5</td>\n",
       "      <td>87.6</td>\n",
       "      <td>87.7</td>\n",
       "      <td>87.8</td>\n",
       "      <td>87.9</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.1</td>\n",
       "      <td>88.2</td>\n",
       "      <td>88.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>28.8</td>\n",
       "      <td>...</td>\n",
       "      <td>88.3</td>\n",
       "      <td>88.4</td>\n",
       "      <td>88.5</td>\n",
       "      <td>88.6</td>\n",
       "      <td>88.7</td>\n",
       "      <td>88.8</td>\n",
       "      <td>88.9</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.1</td>\n",
       "      <td>89.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.7</td>\n",
       "      <td>78.9</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79.1</td>\n",
       "      <td>79.3</td>\n",
       "      <td>79.4</td>\n",
       "      <td>79.5</td>\n",
       "      <td>79.7</td>\n",
       "      <td>79.8</td>\n",
       "      <td>79.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>32.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>...</td>\n",
       "      <td>86.2</td>\n",
       "      <td>86.3</td>\n",
       "      <td>86.5</td>\n",
       "      <td>86.6</td>\n",
       "      <td>86.7</td>\n",
       "      <td>86.9</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.1</td>\n",
       "      <td>87.2</td>\n",
       "      <td>87.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84.3</td>\n",
       "      <td>84.4</td>\n",
       "      <td>84.5</td>\n",
       "      <td>84.6</td>\n",
       "      <td>84.7</td>\n",
       "      <td>84.8</td>\n",
       "      <td>84.9</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.2</td>\n",
       "      <td>85.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>23.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>...</td>\n",
       "      <td>77.3</td>\n",
       "      <td>77.4</td>\n",
       "      <td>77.5</td>\n",
       "      <td>77.7</td>\n",
       "      <td>77.8</td>\n",
       "      <td>77.9</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>78.3</td>\n",
       "      <td>78.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>32.6</td>\n",
       "      <td>32.6</td>\n",
       "      <td>32.6</td>\n",
       "      <td>32.6</td>\n",
       "      <td>32.6</td>\n",
       "      <td>32.6</td>\n",
       "      <td>32.6</td>\n",
       "      <td>32.6</td>\n",
       "      <td>32.6</td>\n",
       "      <td>...</td>\n",
       "      <td>76.8</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.1</td>\n",
       "      <td>77.3</td>\n",
       "      <td>77.4</td>\n",
       "      <td>77.6</td>\n",
       "      <td>77.7</td>\n",
       "      <td>77.8</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>33.7</td>\n",
       "      <td>33.7</td>\n",
       "      <td>33.7</td>\n",
       "      <td>33.7</td>\n",
       "      <td>33.7</td>\n",
       "      <td>33.7</td>\n",
       "      <td>33.7</td>\n",
       "      <td>33.7</td>\n",
       "      <td>33.7</td>\n",
       "      <td>...</td>\n",
       "      <td>74.5</td>\n",
       "      <td>74.6</td>\n",
       "      <td>74.7</td>\n",
       "      <td>74.8</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.1</td>\n",
       "      <td>75.3</td>\n",
       "      <td>75.4</td>\n",
       "      <td>75.5</td>\n",
       "      <td>75.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         country  1800  1801  1802  1803  1804  1805  1806  1807  1808  ...  \\\n",
       "0    Afghanistan  28.2  28.2  28.2  28.2  28.2  28.2  28.1  28.1  28.1  ...   \n",
       "1        Albania  35.4  35.4  35.4  35.4  35.4  35.4  35.4  35.4  35.4  ...   \n",
       "2        Algeria  28.8  28.8  28.8  28.8  28.8  28.8  28.8  28.8  28.8  ...   \n",
       "3        Andorra   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "4         Angola  27.0  27.0  27.0  27.0  27.0  27.0  27.0  27.0  27.0  ...   \n",
       "..           ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "182    Venezuela  32.2  32.2  32.2  32.2  32.2  32.2  32.2  32.2  32.2  ...   \n",
       "183      Vietnam  32.0  32.0  32.0  32.0  32.0  32.0  32.0  32.0  32.0  ...   \n",
       "184        Yemen  23.4  23.4  23.4  23.4  23.4  23.4  23.4  23.4  23.4  ...   \n",
       "185       Zambia  32.6  32.6  32.6  32.6  32.6  32.6  32.6  32.6  32.6  ...   \n",
       "186     Zimbabwe  33.7  33.7  33.7  33.7  33.7  33.7  33.7  33.7  33.7  ...   \n",
       "\n",
       "     2091  2092  2093  2094  2095  2096  2097  2098  2099  2100  \n",
       "0    76.5  76.6  76.7  76.9  77.0  77.1  77.3  77.4  77.5  77.7  \n",
       "1    87.4  87.5  87.6  87.7  87.8  87.9  88.0  88.1  88.2  88.3  \n",
       "2    88.3  88.4  88.5  88.6  88.7  88.8  88.9  89.0  89.1  89.2  \n",
       "3     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4    78.7  78.9  79.0  79.1  79.3  79.4  79.5  79.7  79.8  79.9  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "182  86.2  86.3  86.5  86.6  86.7  86.9  87.0  87.1  87.2  87.3  \n",
       "183  84.3  84.4  84.5  84.6  84.7  84.8  84.9  85.0  85.2  85.3  \n",
       "184  77.3  77.4  77.5  77.7  77.8  77.9  78.0  78.2  78.3  78.4  \n",
       "185  76.8  77.0  77.1  77.3  77.4  77.6  77.7  77.8  78.0  78.1  \n",
       "186  74.5  74.6  74.7  74.8  75.0  75.1  75.3  75.4  75.5  75.7  \n",
       "\n",
       "[187 rows x 302 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pop = pd.read_csv('data/life_expectancy_years.csv')\n",
    "df_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>00s mean</th>\n",
       "      <th>10s mean</th>\n",
       "      <th>20s mean</th>\n",
       "      <th>30s mean</th>\n",
       "      <th>40s mean</th>\n",
       "      <th>50s mean</th>\n",
       "      <th>60s mean</th>\n",
       "      <th>70s mean</th>\n",
       "      <th>80s mean</th>\n",
       "      <th>90s mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>29.70</td>\n",
       "      <td>28.057</td>\n",
       "      <td>30.92</td>\n",
       "      <td>31.54</td>\n",
       "      <td>32.15</td>\n",
       "      <td>35.40</td>\n",
       "      <td>42.62</td>\n",
       "      <td>46.63</td>\n",
       "      <td>44.78</td>\n",
       "      <td>53.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>35.40</td>\n",
       "      <td>33.800</td>\n",
       "      <td>35.40</td>\n",
       "      <td>40.17</td>\n",
       "      <td>44.87</td>\n",
       "      <td>56.97</td>\n",
       "      <td>65.12</td>\n",
       "      <td>69.41</td>\n",
       "      <td>72.34</td>\n",
       "      <td>73.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>29.54</td>\n",
       "      <td>30.690</td>\n",
       "      <td>31.59</td>\n",
       "      <td>34.75</td>\n",
       "      <td>36.91</td>\n",
       "      <td>49.43</td>\n",
       "      <td>55.10</td>\n",
       "      <td>60.04</td>\n",
       "      <td>67.64</td>\n",
       "      <td>72.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>29.35</td>\n",
       "      <td>28.180</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.40</td>\n",
       "      <td>33.30</td>\n",
       "      <td>37.46</td>\n",
       "      <td>43.21</td>\n",
       "      <td>47.11</td>\n",
       "      <td>47.73</td>\n",
       "      <td>49.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>33.80</td>\n",
       "      <td>32.680</td>\n",
       "      <td>36.95</td>\n",
       "      <td>45.35</td>\n",
       "      <td>53.85</td>\n",
       "      <td>60.63</td>\n",
       "      <td>65.22</td>\n",
       "      <td>68.82</td>\n",
       "      <td>72.80</td>\n",
       "      <td>74.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>32.44</td>\n",
       "      <td>32.190</td>\n",
       "      <td>32.68</td>\n",
       "      <td>34.73</td>\n",
       "      <td>46.16</td>\n",
       "      <td>57.38</td>\n",
       "      <td>63.32</td>\n",
       "      <td>67.38</td>\n",
       "      <td>70.88</td>\n",
       "      <td>72.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>31.04</td>\n",
       "      <td>29.650</td>\n",
       "      <td>30.48</td>\n",
       "      <td>31.56</td>\n",
       "      <td>33.42</td>\n",
       "      <td>50.98</td>\n",
       "      <td>55.89</td>\n",
       "      <td>58.77</td>\n",
       "      <td>66.94</td>\n",
       "      <td>70.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>23.55</td>\n",
       "      <td>23.200</td>\n",
       "      <td>23.60</td>\n",
       "      <td>23.70</td>\n",
       "      <td>23.71</td>\n",
       "      <td>27.68</td>\n",
       "      <td>37.12</td>\n",
       "      <td>47.89</td>\n",
       "      <td>55.73</td>\n",
       "      <td>60.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>33.74</td>\n",
       "      <td>31.950</td>\n",
       "      <td>34.38</td>\n",
       "      <td>34.72</td>\n",
       "      <td>36.92</td>\n",
       "      <td>46.56</td>\n",
       "      <td>51.25</td>\n",
       "      <td>55.53</td>\n",
       "      <td>54.52</td>\n",
       "      <td>47.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>34.12</td>\n",
       "      <td>32.540</td>\n",
       "      <td>34.36</td>\n",
       "      <td>34.48</td>\n",
       "      <td>41.05</td>\n",
       "      <td>50.88</td>\n",
       "      <td>54.91</td>\n",
       "      <td>57.39</td>\n",
       "      <td>61.66</td>\n",
       "      <td>53.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 country  00s mean  10s mean  20s mean  30s mean  40s mean  \\\n",
       "0            Afghanistan     29.70    28.057     30.92     31.54     32.15   \n",
       "1                Albania     35.40    33.800     35.40     40.17     44.87   \n",
       "2                Algeria     29.54    30.690     31.59     34.75     36.91   \n",
       "4                 Angola     29.35    28.180     30.73     31.40     33.30   \n",
       "5    Antigua and Barbuda     33.80    32.680     36.95     45.35     53.85   \n",
       "..                   ...       ...       ...       ...       ...       ...   \n",
       "182            Venezuela     32.44    32.190     32.68     34.73     46.16   \n",
       "183              Vietnam     31.04    29.650     30.48     31.56     33.42   \n",
       "184                Yemen     23.55    23.200     23.60     23.70     23.71   \n",
       "185               Zambia     33.74    31.950     34.38     34.72     36.92   \n",
       "186             Zimbabwe     34.12    32.540     34.36     34.48     41.05   \n",
       "\n",
       "     50s mean  60s mean  70s mean  80s mean  90s mean  \n",
       "0       35.40     42.62     46.63     44.78     53.17  \n",
       "1       56.97     65.12     69.41     72.34     73.87  \n",
       "2       49.43     55.10     60.04     67.64     72.87  \n",
       "4       37.46     43.21     47.11     47.73     49.08  \n",
       "5       60.63     65.22     68.82     72.80     74.36  \n",
       "..        ...       ...       ...       ...       ...  \n",
       "182     57.38     63.32     67.38     70.88     72.48  \n",
       "183     50.98     55.89     58.77     66.94     70.07  \n",
       "184     27.68     37.12     47.89     55.73     60.65  \n",
       "185     46.56     51.25     55.53     54.52     47.14  \n",
       "186     50.88     54.91     57.39     61.66     53.58  \n",
       "\n",
       "[184 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pop = df_pop \\\n",
    "        .filter(df_pop.columns[df_pop.columns.str.startswith(('19','country'))])\\\n",
    "        .dropna()\n",
    "\n",
    "#df_pop.shape\n",
    "\n",
    "df_pop2 = pd.DataFrame({'country' : df_pop.loc[:,'country'],\n",
    "                    '00s mean' : df_pop.loc[:,'1900':'1909'].mean(axis=1),\n",
    "                    '10s mean' : df_pop.loc[:,'1910':'1919'].mean(axis=1),\n",
    "                    '20s mean' : df_pop.loc[:,'1920':'1929'].mean(axis=1),\n",
    "                    '30s mean' : df_pop.loc[:,'1930':'1939'].mean(axis=1),\n",
    "                    '40s mean' : df_pop.loc[:,'1940':'1949'].mean(axis=1),\n",
    "                    '50s mean' : df_pop.loc[:,'1950':'1959'].mean(axis=1),\n",
    "                    '60s mean' : df_pop.loc[:,'1960':'1969'].mean(axis=1),\n",
    "                    '70s mean' : df_pop.loc[:,'1970':'1979'].mean(axis=1),\n",
    "                    '80s mean' : df_pop.loc[:,'1980':'1989'].mean(axis=1),\n",
    "                    '90s mean' : df_pop.loc[:,'1990':'1999'].mean(axis=1)})\n",
    "\n",
    "\n",
    "def decade_avg(k):\n",
    "    x = str(1900 + k*10)\n",
    "    y = str(1909 + k*10)\n",
    "    return df_pop.loc[:,x:y].mean(axis=1)\n",
    "\n",
    "df_pop3 = pd.DataFrame({'Country' : df_pop.loc[:,'country']})\n",
    "\n",
    "for i in range(10):\n",
    "    x = str(i) + '0s mean'\n",
    "    df_pop3[str(x)] = decade_avg(i)\n",
    "    \n",
    "df_pop2\n",
    "#print(df_pop3)\n",
    "#df_pop3.loc[:,'90s'].max()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S14x7ZhV3Oke"
   },
   "source": [
    "**Note**: the following 3 questions are regarding the dataset you just created, not the original raw data from CSV.\n",
    "\n",
    "Which country had the highest life expectancy in the 1970s (1970-1979) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "KcHgPtDC3NNv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65    Greece\n",
       "Name: country, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pop2[df_pop2['70s mean'] == df_pop2['70s mean'].max()]['country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mb8TT4h6bmsh"
   },
   "source": [
    "How many countries had at least 1 \"peak\" decade? A peak decade is a decade which had a higher life expectancy compared to both the deacdes before and after it (the 1900s and 1990s cannot be called that here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "4P8PA95Lbmsi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def peak(row):\n",
    "    for i in range(1,9):\n",
    "        before = str(i-1) + '0s mean'\n",
    "        current = str(i) + '0s mean'\n",
    "        after = str(i+1) + '0s mean'\n",
    "        if row[before] < row[current] < row[after]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "df_pop2['peak'] = df_pop2.apply(peak,axis=1)\n",
    "df_pop2['peak'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vlpum99Xbmsk"
   },
   "source": [
    "In which decade did most countries experience a decrease in life expectancy compared to the previous decade? (see if you can think of a reason) E.g. if you check from 1980s to 1990s about 20% of countries decreased in life expectency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "dsVa69HIbmsk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decade that most countries exprience a decrease in life expectancy is 0 to 1.\n",
      "Probably due to the spanish flu\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    current = str(i) + '0s mean'\n",
    "    after = str(i+1) + '0s mean'\n",
    "    x = str(i) + str(i+1) + '_dec'\n",
    "    df_pop2[x] = df_pop2.apply(lambda row: row[current] > row[after],axis=1)\n",
    "    \n",
    "max_dec = df_pop2.loc[:,'01_dec':].sum().argmax()\n",
    "print(f\"The decade that most countries exprience a decrease in life expectancy is {max_dec} to {max_dec+1}.\\nProbably due to the spanish flu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping with BeautifulSoup\n",
    "\n",
    "###### (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to [ebay.com](ebay.com) and search for little boys t-shirts. The ebay website, like any modern website, is filled with text, images and links. But if you are using Google Chrome and you right-click on any page and choose \"View page source\" you will see the raw HTML script behind it. The following code was used to download thousands of boys and girls shirts images from ebay, your mission is to fill in the blanks.\n",
    "\n",
    "Run the following piece of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://il.ebay.com/b/Boys-Tops-Shirts-T-Shirts-for-Boys/260966/bn_1642883?rt=nc&LH_ItemCondition=1000&LH_BIN=1&LH_PrefLoc=3&_pgn=1'\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code imports Beautiful Soup, imports the requests library for handling web connections, assigns an ebay search results page address to a variable called `url`, \"requests\" this URL, stores the response in a variable called `r`, makes a `BeautifulSoup` object out of the response's `content`, and assigns it to a variable called `soup`.\n",
    "\n",
    "It is advised to visit the url using your browser, so you will have a visual understanding of what you are doing.\n",
    "\n",
    "Print the raw HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if IE 9]><html class=\"ie9\" lang=\"en\"><![endif]-->\n",
      "<!--[if gt IE 9]><!-->\n",
      "<html lang=\"en\">\n",
      " <!--<![endif]-->\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"Shop eBay for great deals on Boys Tops, Shirts &amp; T-Shirts for Boys. You'll find new or used products in Boys Tops, Shirts &amp; T-Shirts for Boys on eBay. Free shipping on selected items.\" name=\"description\"/>\n",
      "  <title>\n",
      "   Boys Tops, Shirts &amp; T-Shirts for Boys | eBay\n",
      "  </title>\n",
      "  <meta content=\"unsafe-url\" name=\"referrer\"/>\n",
      "  <meta content=\"Boys Tops, Shirts &amp; T-Shirts for Boys | eBay\" property=\"og:title\"/>\n",
      "  <link href=\"https://ir.ebaystatic.com\" rel=\"'preconnect'\"/>\n",
      "  <meta content=\"34E98E6F27109BE1A9DCF19658EEEE33\" name=\"msvalidate.01\"/>\n",
      "  <meta content=\"Shop eBay for great deals on Boys Tops, Shirts &amp; T-Shirts for Boys. You'll find new or used products in Boys Tops, Shirts &amp; T-Shirts for Boys on eBay. Free shipping on selected items.\" property=\"og:description\"/>\n",
      "  <meta content=\"ebay-o\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the page's title? Replace `#### your code here ####` to get the title as a simple string, without html tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boys Tops, Shirts & T-Shirts for Boys | eBay\n"
     ]
    }
   ],
   "source": [
    "url_title = soup.title.text\n",
    "print(url_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the all hyperlinks on page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_links is a: <class 'list'>\n",
      "\n",
      "first 5 elements in all_links:\n",
      "['https://www.ebay.com/', 'http://www.ebay.com/sch/ebayadvsearch', 'https://signin.ebay.com/ws/eBayISAPI.dll?SignIn&_trksid=m570.l3348', 'https://www.ebay.com/globaldeals', 'https://ocsnext.ebay.com/ocs/home']\n"
     ]
    }
   ],
   "source": [
    "all_links = [link['href'] for link in soup.find_all('a',href=True)[1:]]\n",
    "print('all_links is a: ' + str(type(all_links)))\n",
    "print()\n",
    "print('first 5 elements in all_links:')\n",
    "print(all_links[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the class type of `all_links`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the all images on page (no credit):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "images =  soup.find_all('img', src=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a `list` of all image titles from the `images` object, **except for the first one**. Print that list.\n",
    "\n",
    "Hint: `alt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tommy Hilfiger Baby / Boys / Youth Cotton Polo Shirt NEW WITH TAG ALL Sizes !', 'Chivas Del Guadalajara Youth Centered Full Zipper S Grade Track Soccer Jacket', 'NWT 100% Authentic VILEBREQUIN 100 % Cotton POLO - BLUE - BOYS - 4 Years', \"Disney Boys' Toy Story Snug Fit Cotton Pajamas Size 4, 6, 8, 10\", 'Boys toddler CHAMPION 2 piece outfit sets shirts shorts all sizes colors', \"Boy's School Uniform Short Sleeve Polo Shirt TAGLESS (Sizes, 4-20) NWT\", 'Boys Dress Shirt Solid Long Sleeve Formal Kids Wedding Party Boy Size 5 -18 New', 'Roblox Boys Short Sleeve T-Shirt Officially Licensed Black Large 14/16', \"Polo Ralph Lauren Kids' Golf Shirts White Stripe S 5\", \"Boy's Champion Logo T-shirt Size L New With Tags Color Black\", 'Boys toddler New balance 2 and 3 piece outfit sets shirts tank top shorts', 'Pajama R Us Boys 5 Pack Ribbed Tank Tops Size 2T/3T 4T/5T 4/5 6/8 10/12 14/16 18', 'Polo Ralph Lauren Boys Blue Polo Bear Football Graphic Short Sleeve T-Shirt', 'Nike Dri-Fit Short Sleeve Shirt Youth White/Striped New with Defect', 'Diesel Boys Light Heather Gray Fashion Top Size 4 5 6 7 8 10/12 14 16 $30', 'Youth Boys John Deere Logo Emblem T-Shirt (Green) Size 3T long sleeve', 'Berlioni Italy Toddlers Kids Boys Long Sleeve Dress Shirt Set With Tie & Hanky', \"NEW BOYS LEVI'S GRAPHIC TEE T SHIRT 2 PIECE PACK SET\", 'New w Tag Tommy Hilfiger Boy Toddler Navy T-Shirt Top Back to School', 'BNWT Boys YLG Blue UNDER ARMOUR FREEDOM T Shirt (B1)', 'NEW WITH TAGS Vineyard Vines White T-Shirt Size Small 8-10 Boys Girls', 'Studio 3 Boys Four Pack Assorted Color T-Shirts Size 2T 3T 4T 5T 4 5/6 7', \"NEW!! Nike Boy's Pro Training Dri-Fit Loose Fit Shirts Variety in Size #181\", 'Polo Ralph Lauren Boys Blue Multi Stripe Crew-Neck Short Sleeve T-Shirt', 'Worlds Greatest BIG BROTHER T Shirt Boys Youth Kids and Adult Tee T Shirt', 'Viero Richi Boys Cufflink shirt French Cuff Dress Shirt -Cufflinks Included', 'Polo Ralph Lauren big kids polo bear polo shirts fall grey', \"Boy's Dress Shirt & Tie Set Long Sleeve- Many Colors Available\", 'Polo Ralph Lauren Shirt Boys Youth Large Bear Astronaut Blue TShirt NEW W TAGS ', 'U.S. Polo Assn Boys 5 Pack Tank Tops Size 4T/5T 4/5 10/12 14/16 18/20', 'Studio 3 Boys Four Pack Assorted Color T-Shirts Size 2T 3T 4T 5T 4 5/6 7', \"Pokemon Big Boys Charizard Short Sleeve T-Shirt - Pokemon Gotta Cath 'EM All...\", 'Big Boys CHAMPION short sleeve crewneck t shirts all sizes colors', \"Nautica Boys' Crew Neck T-Shirts  S (8)  M (10/12)  L (14/16) New With Tags\", 'Boys Long Sleeve Dress Shirt Matching Tie & Hanky Toddler Kids Button Up Set', 'Hawaiian Shirts Boys Flower Leaf Beach Aloha Party Camp Holiday Casual', 'Hurley Youth 2-Pack Boys UPF 50+ Tops  Swim Shirt, Blue, White, ', 'Brand NEW - Toddler Boys 2PC T-Shirt And Shorts Set - Choose Size & Color', 'Disney Toy Story Boys Buzz Lightyear T-Shirt - Air Brushed Design Toy Story...', 'Mariokart Boys T Shirt 2 Pk Lot Reeses Peanut Butter Cup Tie Dye Size Small 6/7', 'Polo Ralph Lauren Boys Navy Basketball Polo Bear Graphic Short Sleeve T-Shirt', 'Hanes Boy Tank 5-Pack EcoSmart Undershirt Underwear Breathable Lightweight XS-XL', '2 - New Boys Size 8 Fortnite & Minecraft  T-shirts  - LICENSED -', 'Vineyard Vines Boys Striped Soft Jersey Short Sleeve Pocket T-Shirt', 'UNDER ARMOUR Boys Heatgear & Assorted Style Graphic Logo T-Shirts; Szs 4-7, NWT', 'Polo Ralph Lauren big kids cotton mesh big pony short sleeve polo', 'Roblox Boys Short Sleeve T-Shirt Officially Licensed Black X-Small 4/5', 'New Boys Size 18 T-shirt By Russell']\n"
     ]
    }
   ],
   "source": [
    "image_titles = [image['alt'] for image in images[1:]]    \n",
    "print(image_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need images JPEG addresses. Some have them as attribute `src`, some as attribute `data-src`. This is one way to combine the two. Make sure you understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://i.ebayimg.com/thumbs/images/g/xVAAAOSwba1h-sDI/s-l300.jpg',\n",
       " 'https://i.ebayimg.com/thumbs/images/g/fCMAAOSwpxJkEsIe/s-l300.jpg',\n",
       " 'https://i.ebayimg.com/thumbs/images/g/xgYAAOSwRath7eHS/s-l300.jpg',\n",
       " 'https://i.ebayimg.com/thumbs/images/g/1aYAAOSw~ZNjwlYj/s-l300.jpg',\n",
       " 'https://i.ebayimg.com/thumbs/images/g/leIAAOSwmNVip-W6/s-l300.jpg']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_files_src = [img.get('src', None) for img in images[1:]]\n",
    "image_files_datasrc = [img.get('data-src', None) for img in images[1:]]\n",
    "image_files = [src if datasrc is None else datasrc for src, datasrc in zip(image_files_src, image_files_datasrc)]\n",
    "image_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find a shirt's price.\n",
    "\n",
    "Go to the url in your browser and use the code inspection tool (F12) to look interactively at the url source code. Find the element that holds price data. Notice that the price may be nested within a few levels of html tags. you are searching for the \"lowest\" level, the one that holds the price directly.\n",
    "\n",
    "In our case it is a `span` element with a specific class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the specific class for span elements holding the prices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_class = 's-item__price'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"s-item__price\">ILS 65.34<span class=\"DEFAULT\"> to </span>ILS 90.82</span>, <span class=\"s-item__price\">ILS 131.01</span>, <span class=\"s-item__price\">ILS 182.01</span>, <span class=\"s-item__price\">ILS 81.87</span>, <span class=\"s-item__price\">ILS 29.09<span class=\"DEFAULT\"> to </span>ILS 36.37</span>]\n"
     ]
    }
   ],
   "source": [
    "price_elements = soup.find_all('span', {'class' : price_class})\n",
    "print(price_elements[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From each of these `price_elements` we extract the actual price text with the `get_text` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ILS 131.01\n"
     ]
    }
   ],
   "source": [
    "print(price_elements[1].get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice all prices come with the \"ILS\" prefix and then the number. Also you can see some prices come as a range. For this project we decided to simply take the minimum price of the range.\n",
    "\n",
    "To do so we could split this string to its elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.01\n"
     ]
    }
   ],
   "source": [
    "print(float(price_elements[1].get_text().split(' ')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it in a function and getting all prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_price(price_element):\n",
    "    try:\n",
    "        price = float(price_element.get_text().split(' ')[1])\n",
    "    except:\n",
    "        price = None\n",
    "    return price\n",
    "\n",
    "prices = [parse_price(price_e) for price_e in price_elements]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to actually download the shirts images! The following function accepts an image file address, a shirt title and the file name for the image and attempts to download the image to the current directory with the specified file name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, title, file_name):\n",
    "    try:\n",
    "        response = requests.get(url)    \n",
    "    except:\n",
    "        return '', ''\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    return title, file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the first image from our page, name it 'test.jpg'. Make sure it was downloaded correctly and see what the function returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Tommy Hilfiger Baby / Boys / Youth Cotton Polo Shirt NEW WITH TAG ALL Sizes !',\n",
       " 'test.jpg')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_image(image_files[0], image_titles[0], 'test.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now download all of the page's images, using a loop. \n",
    "\n",
    "First, create a folder named 'boys' in the current directory. You can do it right here in this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file boys already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir boys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the blank to correctly create a dictionary called `images_data` which will hold the `title` of the image, its `file_name`, and the shirt's `price`. Then fill in the blank to correctly download the image with a proper file name using the `download_image` function we wrote for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706920ea0a804bfa9bf7b7b83e4cc2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=48)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "images_data = {'title':{},\n",
    "               'file_name': {},\n",
    "               'price':{}}\n",
    "\n",
    "f = IntProgress(min = 0, max = len(images[1:])) # instantiate a progress bar\n",
    "display(f) # display the bar\n",
    "\n",
    "for i in range(len(images[1:])):\n",
    "    title, file_name = download_image(image_files[i], image_titles[i], 'boys/test_{}.jpg'.format(i))\n",
    "    images_data['title'][i] = title\n",
    "    images_data['file_name'][i] = file_name\n",
    "    images_data['price'][i] = prices[i]\n",
    "    f.value += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that would prove useful later on is having a dataset which summarizes all we have gathered. That's what `images_data` is for. We're going to use `pandas` to make it a `DataFrame` we can easily read and write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>file_name</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tommy Hilfiger Baby / Boys / Youth Cotton Polo...</td>\n",
       "      <td>boys/test0.jpg</td>\n",
       "      <td>65.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chivas Del Guadalajara Youth Centered Full Zip...</td>\n",
       "      <td>boys/test1.jpg</td>\n",
       "      <td>131.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NWT 100% Authentic VILEBREQUIN 100 % Cotton PO...</td>\n",
       "      <td>boys/test2.jpg</td>\n",
       "      <td>182.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disney Boys' Toy Story Snug Fit Cotton Pajamas...</td>\n",
       "      <td>boys/test3.jpg</td>\n",
       "      <td>81.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boys toddler CHAMPION 2 piece outfit sets shir...</td>\n",
       "      <td>boys/test4.jpg</td>\n",
       "      <td>29.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title       file_name   price\n",
       "0  Tommy Hilfiger Baby / Boys / Youth Cotton Polo...  boys/test0.jpg   65.34\n",
       "1  Chivas Del Guadalajara Youth Centered Full Zip...  boys/test1.jpg  131.01\n",
       "2  NWT 100% Authentic VILEBREQUIN 100 % Cotton PO...  boys/test2.jpg  182.01\n",
       "3  Disney Boys' Toy Story Snug Fit Cotton Pajamas...  boys/test3.jpg   81.87\n",
       "4  Boys toddler CHAMPION 2 piece outfit sets shir...  boys/test4.jpg   29.09"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_data_df = pd.DataFrame(images_data)\n",
    "print(images_data_df.shape)\n",
    "images_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was fun, we got 48 images. But we're looking to get times ~200 than that, and the same amount of shirts images for girls. \n",
    "\n",
    "The following function was run to get all boys shirts images. Complete it exactly as we did, but don't run it, we have the images for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False # change this to actually run\n",
    "\n",
    "if run:\n",
    "    boys_url = 'https://il.ebay.com/b/Boys-Tops-Shirts-T-Shirts-for-Boys/260966/bn_1642883?rt=nc&LH_ItemCondition=1000&LH_BIN=1&LH_PrefLoc=3&_pgn='\n",
    "    max_pages = 400\n",
    "    boys_items_data = {'title': {}, 'file_id': {}, 'price': {}}\n",
    "\n",
    "    f = IntProgress(min = 0, max = max_pages)\n",
    "    display(f)\n",
    "\n",
    "    all_items_counter = 0\n",
    "\n",
    "    for page_num in range(1, max_pages):\n",
    "        url = boys_url + str(page_num)\n",
    "        try:\n",
    "            r = requests.get(url, \"lxml\")\n",
    "        except:\n",
    "            print('Stopped at page: ' + page_num)\n",
    "            break\n",
    "        soup = BeautifulSoup(r.content)\n",
    "        images = soup.find_all(\"img\")\n",
    "        image_titles = [x['alt'] for x in images[1:]]\n",
    "        image_files_src = [img.get('src', None) for img in images[1:]]\n",
    "        image_files_datasrc = [img.get('data-src', None) for img in images[1:]]\n",
    "        image_files = [src if datasrc is None else datasrc for src, datasrc in zip(image_files_src, image_files_datasrc)]\n",
    "\n",
    "        try:\n",
    "            assert len(prices) == len(images)\n",
    "        except:\n",
    "            print('Found unequal number of prices in page_num % d' % page_num)\n",
    "            prices = [None] * len(images)\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            title, file_name =  download_image(image_files[i], image_titles[i], 'boys/test_{}_{}.jpg'.format(page_num, i))\n",
    "            boys_items_data['title'][all_items_counter + i] = title\n",
    "            boys_items_data['file_id'][all_items_counter + i] = all_items_counter + i\n",
    "            boys_items_data['price'][all_items_counter + i] = prices[i]\n",
    "        all_items_counter += len(images)\n",
    "        f.value += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap up\n",
    "And that's it, you have used some Pandas to wrangle data and some BeautifulSoup to scrape images from the web. Good luck with the rest of the course!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
